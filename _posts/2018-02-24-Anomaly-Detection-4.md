---
layout: post
title: 异常检测（4）：RS-Forest
category: Machine Learning
author: Hongtao Yu
tags: 
  - machine-learning
  - data-streaming
  - anomaly-detection
comments: true
use_math: true
lang: zh
---

- TOC
{:toc}


# 概论

`RS-Forest`[^RS-Forest] 是一种适用于流数据异常检测的单分类半监督算法。该算法的基础是由多个 `RS-Trees` 驱动的快速且准确的密度估计器。在 RS-Forest 中，每棵树可以在不需要数据的情况下进行随机构建。具体来说，在树构建之前，首先使用统计方法估计整个待检测数据流中的属性范围的潜在演变。 随机挑选的属性的估计范围内的任何值都可以用来分割树。 用这种方式构建的树不仅可以适应流数据不断变化的特性，还可以最大限度地提高系综中树的多样性，实现更精确的密度估计。


当应用于数据流时，RS-Forest 以单一窗口的方式运行。该窗口用来保存新到达的待检测数据。流式 RS-Forest 包括两个主要流程。一个是预测（或评分），另一个是模型更新。流 RS-Forest 认为异常发生在稀疏或低密度区域，异常情况由低密度值表示。流式 RS-Forest 中数据的的异常分是通过其落入的树节点的局部密度定义的。每个到达的实例按其在森林包括的所有树中的平均分进行排序。一旦窗口满了，模型更新就会被触发。

为了加速模型更新，RS-Forest 采用了双节点画像技术。该技术利用固定的树结构，以便同步从新到达的实例捕获节点大小的画像和对同一实例进行预测这两个过程。捕获的节点大小的画像被用于评价下一轮到达窗口的数据。只要数据持续流入，这两个过程就会继续。与现有的基准测试方法相比，流式 RS-Forest 具有较高的异常检测率，较少的运行时间和严格的理论基础。

# 方法

## 基本定义
**定义 1：** RS-Tree 是一个完全二叉树，它通过在随机选择的一个属性上随机选择一个切割点构造。

深度为 $H(H \geq 0)$ 的 RS-Tree 具有 $2^{H + 1} - 1$ 个节点，其中叶节点处于相同的深度 $H$. RS-Tree 来自于随机决策树，树结构无需数据即可构建。构建 RS-Tree 时，算法递归地从数据的属性集中选择一个属性，然后随机选择一个分割点来分割树，直到达到预定的深度 $H$。值得注意的是， 当前的 RS-Tree 仅在连续的属性空间中运行。

**定义 2：** RS-Tree 中的节点概要（profile）被定义为落入该节点所包含区域中的实例的数量。

**定义 3：** 基于 RS-Tree $T$ 的密度估计被定义为：

$$
\hat{f}(x;T)= {\vert \ell({\bf x},T)\vert \over N \mathcal{V}(\ell({\bf x},T))} 
$$


其中 $\ell(x，T)$ 是`终止节点`（termination node），$\vert \cdot \vert$ 是节点大小或节点概要，$\mathcal{V}(\cdot)$ 是节点表示的超矩形的体积。 在 RS-Tree 中，终止节点是用于密度估计的节点。 它可以是叶节点，也可以是满足（即 $\leq$ ）大小限制的第一个节点。为了获得更准确的密度估计性能，需要使用多个 RS-Tree（称为 RS-Forest）构建一个系综。

**定义 4：** 基于 RS-Forest $F$ 的密度估计定义为：

$$
\hat{f}(x;F)={1\over M}\displaystyle\sum_{t=1}^{M}\hat{f}(x;T_{t})
$$

其中 $\hat{f}(x;T_{t})$ 表示由第 $t$ 棵树估计的密度，$M$ 表示树的数量。

## RS-Trees


### 树节点初始化

RS-Tree 的每个节点包含以下元素：（1）变量 $m_l$和 $m_r$，用于交替地记录预测模型中的节点概要或从窗口的流数据中捕获的节点概要; （2）三个节点指针，每个指针分别指向当前节点的左子节点，右子节点和父节点; （3）变量 $v$ 存储当前节点体积与整个属性空间体积的对数比。

### 属性范围估计

确定每个属性的取值范围是构建 RS-Tree 结构的关键步骤。一个狭窄的范围无法满足整个流式数据中的潜在变化。另一方面，范围太大可能会带来不必要的噪音和无用的空间分区。RS-Tree 采用统计策略来估计每个属性的范围。具体地说，首先计算属性 $i$ 的平均值的90％最高后验密度（Hightest Posterior Density,HPD）置信区间 $[LM_i, UM_i]$。然后，通过三西格玛准则放大置信区间，即将下界设为 $LB_i = LM_i - 3\sigma$，上界设为 $UB_i = UM_i + 3\sigma$，其中 $\sigma$ 为属性 $i$ 的标准差。**Algorithm 1** 显示了构建一个 RS-Tree 的算法。

![4-1 Algorithm 1 BuildRS-TreeStructure($LBs, UBs, e, H$)](/assets/blog-images/Anomaly-Detection-4.1.png)



### 节点体积计算

![4-2 （a） 一个 2 维数据的随机空间分区。（b）分区对应的 RS-Tree 结构。](/assets/blog-images/Anomaly-Detection-4.2.png)
**Fig. 4-1.** **（a）** 一个 2 维数据的随机空间分区。**（b）** 分区对应的 RS-Tree 结构。

计算节点体积对于 RS-Tree 进行密度估计至关重要。 一旦 RS-Tree 建立，每个节点的体积是固定的。 如**Fig. 4-1** 所示，空间 $\Omega$ 可以通过 RS-Tree 进行分区。 每个节点表示由 $2^d$ 个不等式 $\mathbf{e^T X} < c$ 形成的超矩形，其中 $\mathbf{e}$ 是仅有一个元素值为 1，其他元素值均为 0 的单位矢量，$\mathbf{x} \in \mathbb{R}^d $，$c \in \mathbb{R}$。 为了计算节点体积，这里首先引入两个引理。

**引理 1：** 设 $\delta^i_j$ 为形成节点 $i$ 所代表的超矩形的属性 $j$ 的长度，则我们有 $ \delta_j^i = l_j \prod_{k=1}^{h_j^i} r_{jk}^i$ ，其中 $l_j$ 表示属性 $j$ 的长度，$r_{jk}^i \in (0, 1)$ 是属性 $j$ 沿着从根节点到节点 $i$ 的路径所进行的第 $k$ 个分割使用的随机数。$h_j^i$ 表示沿着从根节点到节点$i$ 的路径对属性 $j$ 执行的分割总数。

**证明：** 给定区间 $[a，b]$，区间中的随机数 $c$ 可以由公式 $a + s \cdot (b-a)$ 生成，其中$s \in [0,1]$ 是一个随机数。 $[a, c]$ 的长度为 $l \cdot s$， $[c, b]$ 的长度为 $l \cdot s'$，其中 $s' = 1 - s$ 也是 $[0, 1]$ 之间的随机数。 为方便起见，我们记 $\delta_{jk}^k$ 为对属性 $j$ 执行 $k$ 次拆分后属性的长度。 在属性 $j$ 第一个分割后，我们有 $\delta_{j1}^i = l_j \cdot r_{j1}^i$。 假设 $s_1 \in [0, 1]$ 是父节点处选取的随机数。 当前节点是左子节点时，$r_{j1}^i = s_1$; 否则 $r_{j1}^i = 1 - s_1$。 在相同属性的第二次分割中，被分割间隔的长度 $\delta_{j1}^i$。 因此我们有 $\delta_{j2}^i = \delta_{j1}^i \cdot r_{j2}^i - l_j \cdot r_{j1}^i \cdot r_{j2}^i$。 类似地，左子节点 $r_{j2}^i = s_2$，右子节点 $r_{j2}^i = 1 - s_2$，其中 $s_2 \in [0, 1]$ 是父节点处随机选择的值。 基于归纳推理，我们有

$$
\delta_{jh_{j}^{i}}^{i}=l_{j}{\prod}_{k=1}^{h_{j}^{i}}r_{jk}^{i}=\delta_{j}^{i}.
$$

**引理 2：** 设 $V_i$ 为由节点 $i$ 表示的超矩形区域的体积，有 $V_i = V \cdot \prod_{k=1}^{h_i} r_k^i$ ，其中 $r_k^i \in [0, 1]$ 是从根节点到节点 $i$ 的路径上的内部节点处选择的随机数，$V = \prod_{j=1}^d l_j$, $h_i = \sum_{j=1}^d h_j^i$。

引理 2 表明，节点 $i$ 的体积可以通过在从根节点到节点 $i$ 的路径上内部节点使用的随机数来计算。 因此，要计算节点体积，只需在构建 RS-Tree 时记录这些选定的随机数。 有关实现细节，请参阅 **Algorithm 2**。

![4-3 Algorithm 2 ComputeNodeVolRatio($T$)](/assets/blog-images/Anomaly-Detection-4.3.png)


## 流式 RS-Forest

上面所提出的方法使用由 RS-Forest 估计的密度来对流入的实例进行评分，并与用于漂移概念的周期性快速模型更新相结合。在实现中，算法将流数据分割成窗口。根据需求，每个窗口可以具有相同或不同的大小。算法总是在一个窗口中操作，称为最新窗口。在异常检测的初始阶段，系统从样本正常数据中记录节点概要，同时构建树（模型）结构。然后系统对最新窗口中流入的实例进行评分，并同步记录从这些实例捕获的节点概要。一旦窗口已满，模型更新被触发，并通过使用双节点概要技术实现快速模型更新。一旦模型更新完成，旧节点概要将被删除，最新窗口将被清空以迎接新到达的数据。只要数据流入，此过程就会继续进行。

### 异常评分

我们根据 RS-Forest 估算的密度对新来的实例 $x$ 进行评分。一个实例的密度值越低，其异常度越高。结合**定义 3**和**定义 4**，定义 $x$ 的异常评分如下：

$$
{1\over M}\displaystyle\sum_{t=1}^{M}{\vert \ell({\bf x},T_{t})\vert \over N{\cal V}(\ell({\bf x},T_{t}))}
\label{eq:rs-forest4} 
$$

使用**引理 2**, 可以将公式 $\ref{eq:rs-forest4}$ 改写为

$$
{1\over MV}\displaystyle\sum_{t=1}^{M}Score({\bf x}, T_{t}) 
$$

其中 $Score(\mathbf{x},T_t)= \exp(\log( \vert \ell（\mathbf{x},T_t)\vert)- \ell(\mathbf{x},T_t) \cdot v - \log N)$，$V = \prod_{j=1}^d l_j$。实践中，只需要使用 $\sum_{t=1}^m Score(\mathbf{x},T_t)$ 来进行异常排序，因为 $M$ 和  $V$ 都是常量。异常评分的对数缩放是用来避免计算中的下溢。

### 模型的实现。

![4-4 Algorithm 3 & 4](/assets/blog-images/Anomaly-Detection-4.4.png)

**Algorithm 3** 给出了流式 RS-Forest 的实现细节。第1行初始化一个 RS-Forest。在初始化（**Algorithm 4**）阶段，使用 $obtainRange(X)$ 通过样本 $X$ 获得每个属性 $q_i$ 的范围估计。 $X$ 可以是正常实例的样本或数据流的前 $\psi$ 个正常实例。该算法在构建每个 RS-Tree 结构时初始化节点概要。**Algorithm 3** 的第2行使用 $X$ 来更新森林中中每棵树的节点概要 $m_l$。在流式 RS-Forest 模型中，预测（或评分）和模型更新交替发生。在整个执行过程中，每棵树的结构保持不变，从被评分的数据中获得的节点概要将用于下一轮的模型更新。因此，这两个过程有一些共同的操作。在这方面，RS-Forest 采用双节点概要技术来保存在预测阶段中完成的相同操作，然后在模型更新阶段执行。具体而言，使用两个节点概要 $m_l$ 和 $m_r$ 来交替存储当前模型的节点概要（用于对传入数据进行评分）以及从最新窗口中传入的数据中捕获的节点概要（以进行下一轮更新）。处理完 $\psi$ 个数据点后，$m_l$ 和 $m_r$ 的作用发生改变，这种改变的发生由变量 $LR$ 控制。

![4-5 Algorithm 5](/assets/blog-images/Anomaly-Detection-4.5.png)

模型更新是流式 RS-Forest 的关键过程之一。 它的实现总结在 **Algorithm 5** 中。一般地，该过程包括两个主要的功能模块。 一个是异常实例（第3-9行），另一个是正常实例（第10-19行）。 在异常实例情况下，通过对从终止节点到根节点路径上的所有节点概要减一来更新每个 RS-tree。 在正常实例情况下，如果终止节点不是叶节点并且不满足节点大小限制，则通过对沿着从终止节点到叶节点（或者第一个满足大小限制的节点）路径上所有节点概要加一来更新每个 RS-Tree。 这里 $NextChild(child, \mathbf{x})$ 表示 $\mathbf{x}$ 落入的下一个子节点。 值得注意的是，一旦每个实例被打分，流式 RS-Forest 都会收到实例的真实标签，这是在线学习的关键特征。

### 时间和空间的复杂性

如 **Algorithm 3** 所示，主循环中有三个主要操作：（1）预测或评分（第9行）；（2）模型更新（第15行）；（3）节点概要重置（第18行）。在使用当前模型的预测中，实例从每个树的根节点遍历到达终端节点。更新模型时，针对每个异常或正常实例采取两种不同的过程。因为异常实例很少，所以对每个实例花在评分和模型更新上的时间应该等于或小于 $MH$。因此，对 $n$ 个数据点，较差的运行时间是 $O(nMH)$。当触发模型更新时，重置节点概要最多需要 $M \cdot 2^{(H+1)}$。较差的运行时间为 $O(\frac{n}{\psi} M \cdot 2^{(H+1)})$。考虑到 $M$, $H$ 和 $\psi$ 在运行时间内是固定的，我们可以认为流式 RS-Forest 的时间复杂度为 $O(n)$。

在空间复杂性方面，森林本身为 $O(M2^H)$ 。最新窗口的数据缓冲区最多占用 $O(\psi M)$。由于 $\psi$ 和 $M$ 都是较小的常数，这部分空间可以忽略不计。因此，空间复杂度为 $O(2^H)$。在执行过程中，$H$ 是固定的，因此 RS-Forest 的内存使用率对于流数据是恒定的。

# 与 HS-Trees 的对比

与 HS-Trees 不同，RS-Forest 使用多个完全随机化的空间树丛密度估计方面来处理流数据的检测问题，该方法具有扎实的理论基础此外，因为 RS-Forest 共享了预测和模型更新过程的常见操作，因此算法更有效。

![4-6 不同算法在基准数据集上运行时间的比较。](/assets/blog-images/Anomaly-Detection-4.6.png)
**Fig. 4-2.** 不同算法在基准数据集上运行时间的比较。（HS-Trees 在图中被标记为 HSTa）


# Reference

[^RS-Forest]: K. Wu, K. Zhang, W. Fan, A. Edwards, and P. S. Yu, "[RS-Forest: A Rapid Density Estimator for Streaming Anomaly Detection,](https://doi.org/10.1109/ICDM.2014.45)" in *2014 IEEE International Conference on Data Mining,* **2014,** pp. 600-609.




